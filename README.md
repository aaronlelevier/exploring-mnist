# exploring-mnist

The goal for this repo and code is to be learn and understand [Variational autoencoders](https://en.wikipedia.org/wiki/Autoencoder#Variational_autoencoder_(VAE)) and be able to use them with the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) to create a low dimensional continuos space across the 10 digit classes.

This relates to [Generative adversarial networks](https://en.wikipedia.org/wiki/Generative_adversarial_network) and the idea of continuous space between the Generator and Descriminator to avoid mode collapse.

First do this in 2D. Next in 3D.

This repo is for learning. There's too many data science libraries to learn, Linear Algebra, and so on. So this is a scratchpad repo for this learning, and to also serve as a reference / cookbook for how to do things in these libraries.

Doing this with MNIST because it's an image library, multi-dimensional dataset with covariance between features. It can server all needs for this exploration.

## Inspiration

[Intuitively Understanding Variational Autoencoders - Medium Blog](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)

[GAN to WGAN Blog](https://lilianweng.github.io/lil-log/2017/08/20/from-GAN-to-WGAN.html)

[scikit-learn manifold learning](http://scikit-learn.org/stable/modules/manifold.html)

## Other references to look into

Use [seaborn](https://seaborn.pydata.org/) for some plotting

Plot decision boundry like this [SVM example](http://scikit-learn.org/stable/auto_examples/svm/plot_iris.html)
